{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "A parameter is a configuration variable that is internal to the model and whose value can be estimated from data, such as weights in a neural network or coefficients in linear regression.\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "Correlation measures the relationship between two variables, indicating how one variable changes with respect to the other.\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "\n",
        "A negative correlation means that as one variable increases, the other decreases. For example, increased exercise may correlate with decreased body weight.\n",
        "\n",
        "4. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Machine Learning is a subset of AI that enables systems to learn from data and improve over time without being explicitly programmed.\n",
        "\n",
        "Main components:\n",
        "\n",
        "Data\n",
        "\n",
        "Model/Algorithm\n",
        "\n",
        "Loss function\n",
        "\n",
        "Optimizer\n",
        "\n",
        "Evaluation metric\n",
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "A lower loss value indicates the model is making predictions close to the actual values, suggesting better performance.\n",
        "\n",
        "6. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: Numeric and can take infinite values (e.g., age, salary).\n",
        "\n",
        "Categorical variables: Represent categories or groups (e.g., gender, country).\n",
        "\n",
        "7. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Common techniques:\n",
        "\n",
        "Label Encoding\n",
        "\n",
        "One-Hot Encoding\n",
        "\n",
        "Ordinal Encoding\n",
        "\n",
        "8. What do you mean by training and testing a dataset?\n",
        "\n",
        "Training dataset is used to train the model.\n",
        "\n",
        "Testing dataset is used to evaluate the model's performance on unseen data.\n",
        "\n",
        "9. What is sklearn.preprocessing?\n",
        "\n",
        "A module in scikit-learn used for data preprocessing, such as scaling, encoding, and normalization.\n",
        "\n",
        "10. What is a Test set?\n",
        "\n",
        "The test set is the portion of data used to assess the model’s predictive performance after training.\n",
        "\n",
        "11. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "Using:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "12. How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "Understand the problem\n",
        "\n",
        "Collect and clean data\n",
        "\n",
        "Exploratory Data Analysis (EDA)\n",
        "\n",
        "Feature engineering\n",
        "\n",
        "Select and train model\n",
        "\n",
        "Evaluate model\n",
        "\n",
        "Tune and deploy\n",
        "\n",
        "13. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "EDA helps understand data patterns, detect anomalies, and select appropriate features for better model performance.\n",
        "\n",
        "14. What is correlation?\n",
        "\n",
        "In Machine Learning, correlation refers to the statistical relationship between two variables — specifically, how changes in one variable are associated with changes in another.\n",
        "\n",
        " Why is Correlation Important in ML?\n",
        "Feature Selection:\n",
        "\n",
        "Helps identify which features (independent variables) are most relevant to the target variable.\n",
        "\n",
        "Highly correlated features may be redundant and can be removed to simplify the model.\n",
        "\n",
        "Detecting Multicollinearity:\n",
        "\n",
        "In models like linear regression, features that are highly correlated with each other can cause problems (called multicollinearity).\n",
        "\n",
        "Removing one of the correlated features improves model stability.\n",
        "\n",
        "Exploratory Data Analysis (EDA):\n",
        "\n",
        "Correlation helps in understanding the structure of the data before modeling.\n",
        "\n",
        "\n",
        "\n",
        "15. What does negative correlation mean?\n",
        "\n",
        " In Simple Terms:\n",
        "Two variables move in opposite directions.\n",
        "\n",
        " Example:\n",
        "Study Hours and Number of Mistakes:\n",
        "\n",
        "As study hours increase, the number of mistakes tends to decrease.\n",
        "\n",
        "This relationship would show a negative correlation.\n",
        "\n",
        " Interpretation:\n",
        "The correlation coefficient (r) ranges from -1 to +1:\n",
        "\n",
        "r = -1: Perfect negative correlation\n",
        "\n",
        "r < 0: Negative correlation\n",
        "\n",
        "r = 0: No correlation\n",
        "\n",
        "r > 0: Positive correlation\n",
        "\n",
        "16. How can you find correlation between variables in Python?\n",
        "\n",
        "Using:\n",
        "\n",
        "df.corr()\n",
        "To plot:\n",
        "\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.corr(), annot=True)\n",
        "\n",
        "17. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Causation: One variable directly affects another.\n",
        "\n",
        "Correlation: Two variables are related, but not necessarily causally.\n",
        "\n",
        "Example: Ice cream sales and drowning deaths may be correlated (both rise in summer) but one doesn't cause the other.\n",
        "\n",
        "18. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "An optimizer updates model parameters to minimize the loss.\n",
        "\n",
        "Types:\n",
        "\n",
        "SGD: Stochastic Gradient Descent\n",
        "\n",
        "Adam: Adaptive Moment Estimation\n",
        "\n",
        "RMSProp, Adagrad\n",
        "\n",
        "Example:\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "19. What is sklearn.linear_model?\n",
        "\n",
        "A scikit-learn module that provides linear models like:\n",
        "\n",
        "LinearRegression\n",
        "\n",
        "LogisticRegression\n",
        "\n",
        "20. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "model.fit(X, y) trains the model on features X and target y.\n",
        "\n",
        "21. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "model.predict(X) uses the trained model to predict outputs for the input features X.\n",
        "\n",
        "22. What are continuous and categorical variables?\n",
        "\n",
        "In data analysis and machine learning, variables (also called features or attributes) are typically classified into two main types:\n",
        "\n",
        " Continuous Variables:\n",
        "Definition: Variables that can take an infinite number of values within a range.\n",
        "\n",
        "Nature: Quantitative and measurable.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Age (e.g., 23.5 years)\n",
        "\n",
        "Height (e.g., 172.3 cm)\n",
        "\n",
        "Temperature (e.g., 37.6°C)\n",
        "\n",
        "Salary (e.g., ₹45,000.50)\n",
        "\n",
        " These variables are usually numerical and are suitable for mathematical operations like averaging, summing, etc.\n",
        "\n",
        "Categorical Variables:\n",
        "Definition: Variables that represent categories or groups and have a limited number of possible values.\n",
        "\n",
        "Nature: Qualitative and descriptive.\n",
        "\n",
        "Types:\n",
        "\n",
        "Nominal: No inherent order (e.g., gender, color)\n",
        "\n",
        "Ordinal: Have an order or ranking (e.g., education level, satisfaction rating)\n",
        "\n",
        "Examples:\n",
        "\n",
        "Gender: Male, Female\n",
        "\n",
        "Country: India, USA, UK\n",
        "\n",
        "Education Level: High School, Graduate, Postgraduate\n",
        "\n",
        "23. What is feature scaling? How does it help in Machine Learning?\n",
        "Feature scaling normalizes the range of independent variables. It helps algorithms converge faster and improves accuracy.\n",
        "\n",
        "24. How do we perform scaling in Python?\n",
        "\n",
        "Using:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "25. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module in the scikit-learn library that provides tools for preprocessing and transforming data before it is used to train a machine learning model.\n",
        "\n",
        "These tools help in:\n",
        "\n",
        "Scaling features (e.g., StandardScaler, MinMaxScaler)\n",
        "\n",
        "Encoding categorical variables (e.g., LabelEncoder, OneHotEncoder)\n",
        "\n",
        "Handling missing values\n",
        "\n",
        "Normalizing datasets"
      ],
      "metadata": {
        "id": "5NQQV_TqMwXl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0VbpiQxPumu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}